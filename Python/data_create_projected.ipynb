{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File to be created: datasets/projected.hdf5\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import glob, h5py, pickle, cv2, re\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from pandas import read_csv\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "width = 128\n",
    "height = 128\n",
    "channels = 3\n",
    "sub = 'projected'\n",
    "\n",
    "trainpath = '/mnt/HDD04/Projection_data/OUTPUTS/Cascade_AWR2243/' + sub + '_microDoppler/*.png'\n",
    "filename = 'datasets/' + sub + '.hdf5'\n",
    "print('File to be created: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image 48/48 pCemreRony_class6-1_ang0+45_iter4_weight2_proj45.png\n",
      "[0 1 5]\n",
      "(48, 128, 128, 3)\n",
      "(48, 6)\n"
     ]
    }
   ],
   "source": [
    "train_files2 = sorted(glob.glob(trainpath))\n",
    "print(len(train_files2))\n",
    "train_images = []\n",
    "cnt = 1\n",
    "train_labels = []\n",
    "for i in range(len(train_files2)):\n",
    "    fname = train_files2[i].split('/')[-1]\n",
    "    if '\\\\' in fname:\n",
    "        fname = fname.split('\\\\')[-1]\n",
    "    class_idx = [m.end() for m in re.finditer('class', fname)]\n",
    "    underscore_idx = [m.start() for m in re.finditer('_', fname)]\n",
    "    classes = np.array([int(c) for c in fname[class_idx[0]: underscore_idx[1]].split('-')])\n",
    "\n",
    "    angles = fname.split('_')[2][3:]\n",
    "    plusses = angles.rfind('+')\n",
    "    minuses = angles.rfind('-')\n",
    "\n",
    "    if plusses == -1 and minuses == -1:\n",
    "        all_ang_ids = int(angles)\n",
    "        angs = all_ang_ids\n",
    "    elif plusses == -1 and minuses != -1:\n",
    "        all_ang_ids = sorted([minuses, len(angles)+1])\n",
    "    elif plusses != -1 and minuses == -1:\n",
    "        all_ang_ids = sorted([plusses, len(angles)+1])\n",
    "    else:\n",
    "        all_ang_ids = sorted([plusses, minuses, len(angles)+1])\n",
    "\n",
    "    if isinstance(all_ang_ids, list):\n",
    "        if all_ang_ids[0] == 0:\n",
    "            angs = np.zeros((len(all_ang_ids) - 1,), dtype=int)\n",
    "            for i in range(len(all_ang_ids) - 1):\n",
    "                angs[i] = int(angles[all_ang_ids[i]:all_ang_ids[i+1]]) # .astype(int)\n",
    "        else:\n",
    "            angs = np.zeros((len(all_ang_ids),), dtype=int)\n",
    "            angs[0] = int(angles[:all_ang_ids[0]])\n",
    "            for i in range(len(all_ang_ids) - 1):\n",
    "                angs[i+1] = int(angles[all_ang_ids[i]:all_ang_ids[i+1]]) # .astype(int)\n",
    "    proj_ang = int(fname[fname.find('proj')+4: -4])\n",
    "    clas = classes[np.argmax([1 if proj_ang == a else 0 for a in angs])]\n",
    "        \n",
    "    if clas == 13:\n",
    "        clas = 8\n",
    "    elif clas == 14:\n",
    "        clas = 9\n",
    "        \n",
    "    train_labels.append(clas-1)\n",
    "    img = cv2.imread(train_files2[i])\n",
    "    img = cv2.resize(img, (width, height), interpolation=cv2.INTER_CUBIC)# resize to (128,128)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # cv2 load images as BGR, convert it to RGB\n",
    "    clear_output(wait=True)\n",
    "    print('Loading image '+str(cnt)+'/'+str(len(train_files2))+ ' ' + fname)\n",
    "    train_images.append(img)  \n",
    "    cnt += 1\n",
    "print(np.unique(train_labels))\n",
    "train_labels = to_categorical(np.array(train_labels))\n",
    "train_images = np.swapaxes(np.array(train_images), 1, 2).reshape(len(train_images), width, height, channels)/255.\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/projected.hdf5 created.\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(filename, mode='w')\n",
    "f.create_dataset(\"train_img\", train_images.shape, np.uint8)\n",
    "# f.create_dataset(\"test_img\", test_images.shape, np.uint8)  \n",
    "f.create_dataset(\"train_labels\", train_labels.shape, np.uint8)\n",
    "# f.create_dataset(\"test_labels\", test_labels.shape, np.uint8)\n",
    "\n",
    "f[\"train_img\"][...] = train_images\n",
    "# f[\"test_img\"][...] = test_images\n",
    "f[\"train_labels\"][...] = train_labels\n",
    "# f[\"test_labels\"][...] = test_labels\n",
    "f.close()\n",
    "print(filename+' created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
