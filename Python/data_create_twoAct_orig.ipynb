{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File to be created: datasets/twoAct_orig.hdf5\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import glob, h5py, pickle, cv2, re\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from pandas import read_csv\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "width = 128\n",
    "height = 128\n",
    "channels = 3\n",
    "sub = 'twoAct'\n",
    "\n",
    "trainpath = '/mnt/HDD04/Projection_data/OUTPUTS/Cascade_AWR2243/train_' + sub + '/*_orig.png'\n",
    "testpath = '/mnt/HDD04/Projection_data/OUTPUTS/Cascade_AWR2243/test_' + sub + '/*_orig.png'\n",
    "filename = 'datasets/' + sub + '_orig.hdf5'\n",
    "print('File to be created: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image 499/499 pSpot_class4_ang0_iter9_pCemre_class7_ang+45_iter5_orig.png\n",
      "[0 1 2 3 4 5 6 7 8]\n",
      "(499, 128, 128, 3)\n",
      "(499, 2, 9)\n"
     ]
    }
   ],
   "source": [
    "train_files2 = sorted(glob.glob(trainpath))\n",
    "print(len(train_files2))\n",
    "train_images = []\n",
    "cnt = 1\n",
    "train_labels = []\n",
    "for i in range(len(train_files2)):\n",
    "    fname = train_files2[i].split('/')[-1]\n",
    "    if '\\\\' in fname:\n",
    "        fname = fname.split('\\\\')[-1]\n",
    "    class_idx = [m.end() for m in re.finditer('class', fname)]\n",
    "    ang_idx = [m.end() for m in re.finditer('ang', fname)]\n",
    "    underscore_idx = [m.start() for m in re.finditer('_', fname)]\n",
    "    classes = []\n",
    "    classes.append(int(fname[class_idx[0]: underscore_idx[1]]))\n",
    "    classes.append(int(fname[class_idx[1]: underscore_idx[5]]))\n",
    "    classes = np.array(classes)\n",
    "    \n",
    "    for i in range(len(classes)):\n",
    "        if classes[i] == 13:\n",
    "            classes[i] = 8\n",
    "        elif classes[i] == 14:\n",
    "            classes[i] = 9\n",
    "    train_labels.append(classes-1)\n",
    "    img = cv2.imread(train_files2[i])\n",
    "    img = cv2.resize(img, (width, height), interpolation=cv2.INTER_CUBIC)# resize to (128,128)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # cv2 load images as BGR, convert it to RGB\n",
    "    clear_output(wait=True)\n",
    "    print('Loading image '+str(cnt)+'/'+str(len(train_files2))+ ' ' + fname)\n",
    "    train_images.append(img)  \n",
    "    cnt += 1\n",
    "print(np.unique(train_labels))\n",
    "train_labels = to_categorical(np.array(train_labels))\n",
    "train_images = np.swapaxes(np.array(train_images), 1, 2).reshape(len(train_images), width, height, channels)/255.\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image 245/245 pSpot_class4_ang0_iter8_pSpot_class3_ang-45_iter1_orig.png\n",
      "[0 1 2 3 4 5 6 7 8]\n",
      "(245, 128, 128, 3)\n",
      "(245, 2, 9)\n"
     ]
    }
   ],
   "source": [
    "test_files2 = sorted(glob.glob(testpath))\n",
    "print(len(test_files2))\n",
    "test_images = []\n",
    "cnt = 1\n",
    "test_labels = []\n",
    "for i in range(len(test_files2)):\n",
    "    fname = test_files2[i].split('/')[-1]\n",
    "    if '\\\\' in fname:\n",
    "        fname = fname.split('\\\\')[-1]\n",
    "    class_idx = [m.end() for m in re.finditer('class', fname)]\n",
    "    ang_idx = [m.end() for m in re.finditer('ang', fname)]\n",
    "    underscore_idx = [m.start() for m in re.finditer('_', fname)]\n",
    "    classes = []\n",
    "    classes.append(int(fname[class_idx[0]: underscore_idx[1]]))\n",
    "    classes.append(int(fname[class_idx[1]: underscore_idx[5]]))\n",
    "    classes = np.array(classes)\n",
    "    \n",
    "    for i in range(len(classes)):\n",
    "        if classes[i] == 13:\n",
    "            classes[i] = 8\n",
    "        elif classes[i] == 14:\n",
    "            classes[i] = 9\n",
    "    test_labels.append(classes-1)\n",
    "    img = cv2.imread(test_files2[0])\n",
    "    img = cv2.resize(img, (width, height), interpolation=cv2.INTER_CUBIC)# resize to (128,128)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # cv2 load images as BGR, convert it to RGB\n",
    "    clear_output(wait=True)\n",
    "    print('Loading image '+str(cnt)+'/'+str(len(test_files2))+ ' ' + fname)\n",
    "    test_images.append(img)  \n",
    "    cnt += 1\n",
    "print(np.unique(test_labels))\n",
    "test_labels = to_categorical(np.array(test_labels))\n",
    "test_images = np.swapaxes(np.array(test_images), 1, 2).reshape(len(test_images), width, height, channels)/255.\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/twoAct_orig.hdf5 created.\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(filename, mode='w')\n",
    "f.create_dataset(\"train_img\", train_images.shape, np.uint8)\n",
    "f.create_dataset(\"test_img\", test_images.shape, np.uint8)  \n",
    "f.create_dataset(\"train_labels\", train_labels.shape, np.uint8)\n",
    "f.create_dataset(\"test_labels\", test_labels.shape, np.uint8)\n",
    "\n",
    "f[\"train_img\"][...] = train_images\n",
    "f[\"test_img\"][...] = test_images\n",
    "f[\"train_labels\"][...] = train_labels\n",
    "f[\"test_labels\"][...] = test_labels\n",
    "f.close()\n",
    "print(filename+' created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
